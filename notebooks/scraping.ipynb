{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ecd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2136ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '星辰之主',\n",
       " 'tags': ['连载中', '科幻', '星空', '未来高武', '伪科幻'],\n",
       " 'serial_status': '连载中',\n",
       " 'category': '科幻',\n",
       " 'word_count': '7498927',\n",
       " 'author': '减肥专家'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_zongheng(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, \"html.parser\")\n",
    "    title = soup.find(\"div\", attrs={\"class\": \"book-info--title\"}).get_text(strip=True)\n",
    "    div_tags = soup.find(\"div\", attrs={\"class\": \"book-info--tags\"})\n",
    "    tags = []\n",
    "    serial_status = None\n",
    "    category = None\n",
    "    for span in div_tags.find_all(\"span\"):\n",
    "        try:\n",
    "            if span[\"class\"][0] == \"serialStatus\":\n",
    "                # serial_status = \"ongoing\" if span.get_text(strip=True) == \"连载中\" else \"completed\"\n",
    "                serial_status = span.get_text(strip=True)\n",
    "                tags.append(serial_status)\n",
    "            elif span[\"class\"][0] == \"cateFineId\":\n",
    "                category = span.get_text(strip=True)\n",
    "                tags.append(category)\n",
    "        except KeyError:\n",
    "            tags.append(span.get_text(strip=True))\n",
    "    recent_chapter_info = soup.find(\n",
    "        \"div\", attrs={\"class\": \"book-info--chapter-name\"}\n",
    "    ).find(\n",
    "        \"a\", attrs={\"class\": \"global-hover\"}\n",
    "    )\n",
    "    word_count = recent_chapter_info[\"title\"].split(\"字数：\")[1].split()[0]\n",
    "    author = soup.find(\"a\", attrs={\"class\": \"author-info--name\"}).get_text(strip=True)\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"tags\": tags,\n",
    "        \"serial_status\": serial_status,\n",
    "        \"category\": category,\n",
    "        \"word_count\": word_count,\n",
    "        \"author\": author,\n",
    "    }\n",
    "\n",
    "scrape_zongheng(\"https://www.zongheng.com/detail/325639\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "00ca7ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '见春天',\n",
       " 'tags': ['原创', '言情', '近代现代', '爱情', '完结', '花季雨季', '情有独钟', '阴差阳错', '校园', '正剧'],\n",
       " 'serial_status': '完结',\n",
       " 'category': None,\n",
       " 'word_count': 191449,\n",
       " 'author': '纵虎嗅花'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_jjwxc(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, \"html.parser\")\n",
    "    title = soup.find(\"span\", attrs={\"itemprop\": \"articleSection\"}).get_text(strip=True)\n",
    "    tags = soup.find(\"span\", attrs={\"itemprop\": \"genre\"}).get_text(strip=True).split(\"-\")\n",
    "    serial_status = soup.find(\"span\", attrs={\"itemprop\": \"updataStatus\"}).get_text(strip=True)\n",
    "    word_count = int(soup.find(\"span\", attrs={\"itemprop\": \"wordCount\"}).get_text(strip=True)[:-1])\n",
    "    tags.append(serial_status)\n",
    "    extra_tags = soup.find_all(\"div\", attrs={\"class\": \"smallreadbody\"})\n",
    "    for div in extra_tags:\n",
    "        if div.find(\"span\") is not None:\n",
    "            extra = div.find_all(\"a\", attrs={\"style\": \"text-decoration:none;color: red;\"})\n",
    "            for a in extra:\n",
    "                tags.append(a.get_text(strip=True))\n",
    "    author = soup.find(\"span\", attrs={\"itemprop\": \"author\"}).get_text(strip=True)\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"tags\": tags,\n",
    "        \"serial_status\": serial_status,\n",
    "        \"category\": None,\n",
    "        \"word_count\": word_count,\n",
    "        \"author\": author,\n",
    "    }\n",
    "\n",
    "scrape_jjwxc(\"https://www.jjwxc.net/onebook.php?novelid=6079968\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_17k(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_qidian(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, \"html.parser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
